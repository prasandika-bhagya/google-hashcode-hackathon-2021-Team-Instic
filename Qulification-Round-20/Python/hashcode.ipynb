{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import sys\n",
    "import copy\n",
    "\n",
    "def load_data(file_name):\n",
    "    data = {}\n",
    "    with io.open(file_name) as f:\n",
    "        books, libraries, days = f.readline()[:-1].split(\" \")\n",
    "        data[\"books_number\"] = int(books)\n",
    "        data[\"librs_number\"] = int(libraries)\n",
    "        data[\"days\"] = int(days)\n",
    "        data[\"books_scores\"] = {idx: int(val) for idx, val in enumerate(f.readline()[:-1].split(\" \"))}\n",
    "        data[\"librs\"] = {}\n",
    "        for lib in range(int(libraries)):\n",
    "            b, s, sh = f.readline()[:-1].split(\" \")\n",
    "            data[\"librs\"][lib] = {}\n",
    "            data[\"librs\"][lib][\"books\"] = int(b)\n",
    "            data[\"librs\"][lib][\"signup\"] = int(s)\n",
    "            data[\"librs\"][lib][\"ship\"] = int(sh)\n",
    "            data[\"librs\"][lib][\"books_ids\"] = [int(b) for b in f.readline()[:-1].split(\" \")]\n",
    "            temp_to_sort = [(idx, data[\"books_scores\"][idx]) for idx in data[\"librs\"][lib][\"books_ids\"]]\n",
    "            data[\"librs\"][lib][\"sorted_books_ids\"] = [j[0] for j in sorted(temp_to_sort, key=lambda x: x[1], reverse=True)]\n",
    "            data[\"librs\"][lib][\"total_score\"] = sum([data[\"books_scores\"][i] for i in data[\"librs\"][lib][\"books_ids\"]])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(data, out_file, flag0=True):\n",
    "    libs = data[\"librs\"]\n",
    "    sorted_libs = {k: v for k, v in sorted(libs.items(), key=lambda item: item[1][\"total_score\"], reverse=True)}\n",
    "    \n",
    "    sent = set()\n",
    "    for l in sorted_libs:\n",
    "        score = 0\n",
    "        duplicate_books_ids = []        \n",
    "        for book in sorted_libs[l][\"sorted_books_ids\"]:\n",
    "            if book in sent:\n",
    "                score += data[\"books_scores\"][book]\n",
    "                duplicate_books_ids.append(book)\n",
    "                continue\n",
    "            sent.add(book)\n",
    "        sorted_libs[l][\"duplicates_scores\"] = sorted_libs[l][\"total_score\"] - score\n",
    "        sorted_libs[l][\"new_sorted_books_ids\"] = list(set(sorted_libs[l][\"sorted_books_ids\"]) - set(duplicate_books_ids))\n",
    "\n",
    "    # sorted_libs = {k: v for k, v in sorted(libs.items(), key=lambda item: item[1][\"ship\"], reverse=True)}\n",
    "    sorted_libs = {k: v for k, v in sorted(libs.items(), \n",
    "                   key=lambda item: len(item[1][\"new_sorted_books_ids\"]),\n",
    "                   reverse=True)\n",
    "                   }\n",
    "    days = data[\"days\"]\n",
    "    count_libs = 0\n",
    "    output_dict = {}\n",
    "    already_shipped = []\n",
    "    for lib in sorted_libs:\n",
    "        if days <= 0:\n",
    "           break\n",
    "        output_dict[lib] = {}        \n",
    "        books_window = days - sorted_libs[lib][\"signup\"]\n",
    "        books_per_day = sorted_libs[lib][\"ship\"]\n",
    "        shiped_books = []\n",
    "        to_ship = sorted_libs[lib][\"new_sorted_books_ids\"]\n",
    "        for remaining_day in range(books_window):\n",
    "            for per_day in range(books_per_day):\n",
    "                if not to_ship:\n",
    "                    break\n",
    "                curr_book = to_ship.pop(0)\n",
    "                shiped_books.append(curr_book)\n",
    "        output_dict[lib][\"books\"] = shiped_books\n",
    "        output_dict[lib][\"len\"] = len(shiped_books)\n",
    "        count_libs += 1\n",
    "        days -= sorted_libs[lib][\"signup\"]\n",
    "    \n",
    "    with open(out_file, \"w\") as wf:\n",
    "        if flag0:\n",
    "            count_libs -= 1\n",
    "        count_libs = sum([1 for l in output_dict if output_dict[l][\"books\"]])\n",
    "        wf.write(str(count_libs) + \"\\n\")\n",
    "        c = 0\n",
    "        for l in output_dict:\n",
    "            if output_dict[l][\"books\"]:\n",
    "                wf.write(str(l) + \" \" + str(output_dict[l][\"len\"]) + \"\\n\")\n",
    "                for shiped in output_dict[l][\"books\"]:\n",
    "                    wf.write(str(shiped) + \" \")\n",
    "                c += 1\n",
    "                if c < len(output_dict.keys()):\n",
    "                    wf.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'books_number': 6, 'librs_number': 2, 'days': 7, 'books_scores': {0: 1, 1: 2, 2: 3, 3: 6, 4: 5, 5: 4}, 'librs': {0: {'books': 5, 'signup': 2, 'ship': 2, 'books_ids': [0, 1, 2, 3, 4], 'sorted_books_ids': [3, 4, 2, 1, 0], 'total_score': 17}, 1: {'books': 4, 'signup': 3, 'ship': 1, 'books_ids': [0, 2, 3, 5], 'sorted_books_ids': [3, 5, 2, 0], 'total_score': 14}}}\n"
     ]
    }
   ],
   "source": [
    "data_a = load_data(\"a_example.txt\")\n",
    "print(data_a)\n",
    "process(data_a, \"a_example-out.txt\", flag0=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_b = load_data(\"b_read_on.txt\")\n",
    "# print(data_b)\n",
    "process(data_b, \"b_read_on-out.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_c = load_data(\"c_incunabula.txt\")\n",
    "# print(data_c)\n",
    "process(data_c, \"c_incunabula-out.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_e = load_data(\"e_so_many_books.txt\")\n",
    "# print(data_e)\n",
    "process(data_e, \"e_so_many_books-out.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_f = load_data(\"f_libraries_of_the_world.txt\")\n",
    "# print(data_f)\n",
    "process(data_f, \"f_libraries_of_the_world-out.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_d = load_data(\"d_tough_choices.txt\")\n",
    "# print(data_d)\n",
    "process(data_d, \"d_tough_choices-out.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
